\section*{Member contributions}

\subsubsection*{Christopher Klammt}

Main focus was the analysis of the preprocessed dataset and providing insights for the milestone, before extracting features. After feature extraction hate speech statistics were drawn out to show what signifies hate speech. Ad\-di\-tio\-nal\-ly, the semantic features and the SVM classifier were added. Before tackling the problem of the unbalanced dataset, literature research was executed to identify possible approaches. To handle the unbalanced dataset undersampling in the form of randomly deleting over\-re\-pre\-sen\-ted instances and oversampling using synthetic generation of underrepresented instances (via SMOTE) was implemented.

Challenges were faced when trying to provide meaningful insights into the hate speech statistics as a lot of features were count-based and e.g. did not contain the occurring laughing expression or PoS pattern. Furthermore, balancing the dataset did not fare well for performance and it was not possible to apply SMOTE for the neural network approach.

Responsibility was assumed for assignment one and four.

\subsubsection*{Felix Hausberger}

First proper literature research\footnote{see \url{https://github.com/fidsusj/HateSpeechDetection/blob/main/docs/research/papers_overview.md}} was executed on which datasets to use and how to define the project idea, research question and the scope of the project including its novelties. Based on the two utilized datasets found during research the data preparation and corpus building got implemented. For the purpose of data exploration, a Word2Vec model to visualize hate speech word embeddings with t-SNE was added. Also the setup for the GitHub actions and hooks for CI was done.

Then literature research continued on which features and classifiers to use for hate speech detection\footnote{see https://github.com/fidsusj/HateSpeechDetection/blob/main/docs/research/results.md}. Therefore, individual features were grouped and the extraction of n-gram dictionaries and a PoS-tag pattern dictionary was implemented together with the extraction of detected instance counts used as features. Furthermore, the sentiment-based polarity score using VADER and topic classification based on LDA were added as additional features. Afterwards, the Logistic Regression classifier was added to the reusable pipeline and feature importance scores were extracted for each classifier during analysis.

Challenges were mainly faced during the design and engineering phase of the project, i.e. which datasets, features and classifiers to use. Also the question how the data should be preprocessed and harmonized had to be dealt with. A left open challenge is to improve the PoS-tag pattern dictionary to better differentiate between hate speech and non-hate speech. 

Responsibility was assumed for assignment three and four.

\subsubsection*{Nils Krehl}

Literature research for the following papers \footnote{see \url{https://github.com/fidsusj/HateSpeechDetection/blob/main/docs/research/papers_overview.md\#ieee-vpn-required-for--marked-papers}} was done and based upon it the project idea, the research question and the scope of the project including its novelties were defined. 
For the purpose of data exploration, a fasttext model to visualize hate speech word embeddings with t-SNE was added. In contrast to the Word2Vec model two clusters for hate speech and neutral speech are nicely visible. One major contribution was the end to end technical architecture of the project. As part of this, reusable pipelines for feature extraction and classifier execution were developed. New features and classifiers can easily be added to the pipeline. As part of the pipeline the optimal hy\-per\-pa\-ra\-me\-ters are automatically learned by executing \textit{RandomizedSearchCV} and the classifier performance metrics are calculated automatically. The Random Forest and Decision Tree classifiers as well as the neural network baseline via LSTM was realized for evaluation. Based on the literature research regarding feature groups, promising features such as TFIDF, dictionaries and special characters are implemented and visualized.

Challenges were faced in optimizing the execution time of the classifier pipeline, which made the change from \textit{GridSearchCV} to \textit{RandomizedSearchCV} and the use of multiprocessing necessary. Through both measures, it was possible to reduce the execution time to around 10min.

Responsibility was assumed for assignment two and four.
